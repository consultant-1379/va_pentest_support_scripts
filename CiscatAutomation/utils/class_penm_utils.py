import concurrent.futures
import glob
import json
import logging
import os
import re
import ipaddress
import subprocess
import time

import paramiko
import socket
from paramiko.ssh_exception import SSHException



class pENMUtils():
    def __init__(self, target, instance):
        logging.basicConfig(
            filename=os.path.join(os.path.expanduser('~'), 'scriptCiscat', 'ciscatexecutor.log'),
            level=logging.INFO,
            format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s - [%(funcName)s]: %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
        )
        self.target = target
        self.instance = instance
        self.SUDO_FLAG = True
        self.my_path = os.path.join(os.path.expanduser('~'), 'scriptCiscat')
        self.ASSESSOR_PATH = 'C:\\Users\\Public\\Documents\\assessor'
        self.counter = 0
        self._ip_by_subnet = {}
        self.unique_vm = []
        try:
            full_ip_list = self._remove_duplicates(self._extract_ips_from_file())
            subnets_list = self._extract_cidr_subnet_definitions_from_file()
            for subnet in subnets_list:
                #sub = subnet.split('=')[1]
                sub = re.split(':|=', subnet)[1]
                self._ip_by_subnet[sub] = self._find_addresses_in_subnet(full_ip_list, sub)
            self.credentials_list = self._get_credentials()
        except Exception as err:
            logging.error(err)
            raise Exception(f'Missed data for {target} {instance}')
        if len(self.credentials_list) == 0:
            raise Exception(f'No valid credentials found in {os.path.join(self.my_path, 'resources', self.target, 
                                                                          self.instance, 'credentials.txt')}')
        logging.info('End of constructor')

    @property
    def ips_by_subnet(self):
        return self._ip_by_subnet

    def _extract_ips_from_file(self):

        pattern = re.compile(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b')
        # Open the file and read its contents
        with open(os.path.join(self.my_path, 'resources', self.target, self.instance, 'MASTER_siteEngineering.txt'), 'r') as file:
            contents = file.read()
        # Match all instances of the IP address pattern in the contents
        matches = re.findall(pattern, contents)
        # Return a list of the matched IP addresses
        return matches

    def _find_addresses_in_subnet(self, ip_list, subnet):

        # Initialize an empty list to store the found IP addresses
        addresses = []
        # Convert the subnet to an IPv4Network object
        subnet_mask = ipaddress.IPv4Network(subnet)
        # Check each IP address in the list to see if it's in the subnet
        for ip in ip_list:
            if ipaddress.IPv4Address(ip) in subnet_mask:
                addresses.append(ip)
        # Return the list of IP addresses in the subnet
        return addresses

    def _extract_cidr_subnet_definitions_from_file(self):
        """
        Extract subnet definitions in CIDR notation from a text file and return a list.

        :param file_path: str - Absolute path of the text file
        :return: list - List of subnet definitions in CIDR notation extracted from the file
        """

        # Compile a regular expression pattern to match CIDR subnet definitions
        pattern = re.compile(r'.+\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}/\d{1,2}')

        # Open the file and read its contents
        with open(os.path.join(self.my_path, 'resources', self.target, self.instance, 'MASTER_siteEngineering.txt'), 'r') as file:
            contents = file.read()

        # Match all instances of the CIDR subnet definition pattern in the contents
        matches = re.findall(pattern, contents)
        matches = [m.replace('"', '').replace(' ', '') for m in matches]
        # Return the list of matched subnet definitions
        return matches

    def _remove_duplicates(self, input_list):
        """
        Remove all duplicated elements from a list and return the modified list.

        :param input_list: list - The list to remove duplicates from
        :return: list - The modified list with all duplicates removed
        """

        # Convert the list to a set to remove duplicates
        unique_set = set(input_list)

        # Convert the set back to a list
        unique_list = list(unique_set)

        # Return the modified list with all duplicates removed
        return unique_list

    def properties_4_host(self, ip):
        res = self.check_ip(ip)
        if res:
            self.create_property_file(res)
            return f'{ip} : done'
        return f'{ip} : Not available for scanning.'

    def _get_credentials(self):
        '''
        :return:  [{'key': 'vm_private_key', 'username': 'cloud-user'}, {'password': '12shroot', 'username': 'litp-admin'}, {'password': 'veritas', 'username': 'support'}]
        '''
        with open(os.path.join(self.my_path, 'resources', self.target, self.instance, 'credentials.txt'), 'r') as file:
            contents = file.read()
        rows = contents.splitlines()
        creds = []
        for row in rows:
            tmp = row.strip()
            if tmp.startswith('#'):
                continue
            if not re.match(r'^username=[^ =]+ (password|key)=[^ =]+$', tmp):
                logging.warning(f'Invalid credential "{tmp}" found in {os.path.join(self.my_path, 'resources', self.target, 
                                                                            self.instance, 'credentials.txt')}')
                continue
            username = row.split()[0].split('=')[1]
            password_type = row.split()[1].split('=')[0]
            password_or_key_value = row.split()[1].split('=')[1]
            creds.append({'username': username, password_type: password_or_key_value})
        return creds

    def check_ip(self, ip):
        self.unique_vm = []
        pattern = r'^(\D+)\-(\d+)\-([^ ]+)'
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        for credential in self.credentials_list:
            try:
                # Try to connect to the machine using the credentials
                if list(credential.keys())[1] == 'key':
                    k = paramiko.RSAKey.from_private_key_file(os.path.join(self.my_path, 'resources', self.target,
                                                                           self.instance, credential['key']))
                    ssh.connect(ip, username=credential['username'], pkey=k, timeout=10, banner_timeout=10)
                else:
                    ssh.connect(ip, username=credential['username'], password=credential['password'],
                                timeout=10, banner_timeout=200)
                stdin, stdout, stderr = ssh.exec_command("hostname")
                hostname = stdout.read().decode().strip('\n')
                print(f'Found {hostname}')
                #
                token = re.match(pattern, hostname)
                if token and len(token.groups()) == 3:
                    if token.group(3) in self.unique_vm:
                        logging.info(f'an instance of {hostname} is already present. Skipped.')
                        return None
                    self.unique_vm.append(token.group(3))
                #
                # read os version
                stdin, stdout, stderr = ssh.exec_command("cat /etc/os-release")
                tmp = stdout.read().decode()
                name_match = re.search(r'PRETTY_NAME="([^"]+)"', tmp)
                if name_match:
                    os_name = name_match.group(1)
                else:
                    os_name = 'no_name'
                result = {'hostname': hostname, 'ip': ip, 'username': credential['username'],
                          list(credential.keys())[1]: credential[list(credential.keys())[1]], 'os': os_name}
                # to reverse the command use:  sudo gpasswd -d litp-admin wheel
                if credential['username'] == 'litp-admin' and self.SUDO_FLAG:
                    logging.info(f'add sudoer for litp-admin')
                    shell = ssh.invoke_shell()
                    shell.send("su root\n")
                    while not 'Password' in shell.recv(1024).decode():
                        pass
                    shell.send('12shroot' + "\n")
                    out = shell.recv(1024).decode()
                    while not 'litp-admin' in out:
                        out = shell.recv(1024).decode()
                    shell.send('usermod -aG wheel litp-admin' + '\n')
                    out = shell.recv(1024).decode()
                    while not 'litp-admin' in out:
                        out = shell.recv(1024).decode()
                    ssh.close()
                ssh.close()
                return result
            except  paramiko.SSHException as e:
                # print(f"Error paramiko.SSHException for {ip} credential  {credential['username']},"
                #       f'{credential[list(credential.keys())[1]]} --> {e}')
                # out_list.append(f'FAILED ip={ip}: {e}')
                logging.warning(f"Fail in authentication on  {ip} for invalid credentials : {credential['username']},"
                                f"{credential[list(credential.keys())[1]]}")
            except TimeoutError as e:
                # print(f'Error TimeoutError for {ip} credential  {credential['username']},'
                #       f'{credential[list(credential.keys())[1]]} --> {e}')
                # out_list.append(f'FAILED ip={ip}: {e}')
                logging.warning(f"Fail in authentication on  {ip} for Timeout")
                return None
            except Exception as err:
                logging.error(f"Unexpected error authenticating on  {ip} ; {err}")
                print(f"Unexpected error authenticating on  {ip} ; {err}")
                return None

    # def split_hosts_list(full_list, chunk:int, files_path):
    #     if chunk < 1 :
    #         raise Exception(f'Invalid chunk size {chunk}')
    #     l = len(full_list)
    #     if l == 0:
    #         raise Exception(f'Wrong list size, the ip list is empty, check the connections')
    #     #num_of_files = math.ceil(l / chunk)
    #
    #     file_list = glob.glob(os.path.join(files_path, 'host_list_*'))
    #     for file_path in file_list:
    #         try:
    #             os.remove(file_path)
    #             print(f"Removed file: {file_path}")
    #         except OSError as e:
    #             print(f"Error removing file: {file_path} - {e}")
    #
    #
    #     count = 1
    #     file_index = 1
    #     for row in full_list:
    #         if count == 1 :
    #             f = open(os.path.join(files_path, f'host_list_{file_index}'), 'w+')
    #         f.write(f'{row}\n')
    #         if count == chunk:
    #             count = 1
    #             file_index+=1
    #             f.close()
    #         else:
    #             count+=1
    #
    def create_property_file(self, data:dict):

        output_file = os.path.join(self.my_path, 'resources', self.target, self.instance, 'properties',
                                   f"{data['hostname']}.properties")
        with open(output_file, 'w') as outfile:

            outfile.write(f"session.1.type=ssh\n")
            outfile.write(f"session.1.host={data['ip']}\n")
            outfile.write(f"session.1.user={data['username']}\n")

            if 'key' in list(data.keys()):
                key_file = os.path.join(self.my_path, 'resources', self.target, self.instance, data['key']).replace('\\', '\\\\')
                outfile.write(f"session.1.identity={key_file}\n")
            else:
                outfile.write(f"session.1.cred={data['password']}\n")
            outfile.write(f"session.1.port=22\n")
            outfile.write(f"#session.1.tmp=path\n\n")
            outfile.write(f"#os={data['os']}\n")

    #
    # def test():
    #     global counter
    #     counter+=1
    #
    # def execute_command(data):
    #     command = data[0]
    #     output = data[1]
    #     logger = data[2]
    #     progress = data[3]
    #     self.test()
    #     t0 = time.time()
    #     with open(output, 'w') as f:
    #         logger(f'Executing {progress} : \n{command}')
    #         try:
    #             result = subprocess.run(command, text=True, stdout=f, check=True)
    #         except subprocess.CalledProcessError as err:
    #             f.write(f'CISCAT exited with error : {err}\n')
    #         except subprocess.SubprocessError as err:
    #             f.write(f'Error executing CISCAT batch file : {err}\n')
    #         except Exception as err:
    #             f.write(f'Unexpected error executing CISCAT : {err}\n')
    #         f.write(f'Errors -> {result.stderr}\n')
    #         f.write(f'Return code -> {result.returncode}\n')
    #         ex_time = int((time.time()-t0)/60)
    #         f.write(f'Execution time -> {ex_time} minutes\n')
    #         logger(f'Ended {progress} : \n{command}  Execution time -> {ex_time} minutes')
    #
    #     # return the output and the exit code as a tuple
    #     print(f'End of {output}. Executed in {ex_time} minutes')
    #     return result.returncode
    #
    # def find_benchmark(filename, os):
    #     with open(filename) as f:
    #         # Load JSON data from file
    #         data = json.load(f)
    #
    #     # Now you can access your data as a Python object
    #     for i in data:
    #         if i['os'] == os:
    #             return i['benchmark']
    #
    # def extract_os(filename):
    #     with open(filename, 'r') as file:
    #         for line in file:
    #             # Remove leading and trailing spaces and check if it starts with '#os'
    #             stripped_line = line.strip()
    #             if stripped_line.startswith('#') and 'os' in stripped_line:
    #                 key, value = stripped_line.split('=', 1)  # Split the line into key and value at the first equals sign
    #                 return value.strip()  # Remove leading and trailing spaces from the value
    #
    # def create_ciscat_command(benchmark, profile, sessions_properties, report_path):
    #     return [
    #            'C:\\Users\\Public\\Documents\\assessor\\Assessor-CLI.bat',
    #            '-b',
    #            benchmark,
    #            '-p',
    #            profile,
    #            '-sessions',
    #            sessions_properties,
    #            '-rd',
    #            report_path,
    #            '-csv',
    #            '-html'
    #     ]
    #
    # # def create_commands_list(target, instance):
    # #     property_files = [os.path.abspath(file) for file in glob.glob(os.path.join(my_path, 'resources', target, instance,
    # #                                                                                'properties', '*.properties'))]
    # #     commands = []
    # #     for sess_prop in property_files:
    # #         cmd = ' '.join(create_ciscat_command(benchmark, profile, sess_prop, reports_path))
    # #         commands.append(cmd)
    # #     pass
    #
    # def run_job(target, instance, logger, benchmark='CIS_Red_Hat_Enterprise_Linux_7_Benchmark_v3.1.1-xccdf.xml', profile='"Level 2 - Server"'):
    #
    #     to_remove = glob.glob(os.path.join(my_path, 'reports', target, instance, '*'))
    #     for file_path in to_remove:
    #         try:
    #             os.remove(file_path)
    #             print(f"Removed file: {file_path}")
    #         except OSError as e:
    #             print(f"Error removing file: {file_path} - {e}")
    #
    #     property_files = [os.path.abspath(file) for file in glob.glob(os.path.join(my_path, 'resources', target, instance,
    #                                                                       'properties', '*.properties'))]
    #     benchmark = os.path.join(assessor_path, 'benchmarks', benchmark)
    #     profile = profile
    #     reports_path = os.path.join(my_path, 'reports', target, instance)
    #     commands = []
    #     for sess_prop in property_files:
    #         cmd = ' '.join(create_ciscat_command(benchmark, profile, sess_prop, reports_path))
    #         commands.append(cmd)
    #     jobs = []
    #     for c in commands:
    #         progress = f'{len(jobs)+1} of {len(commands)}'
    #         jobs.append([c, os.path.join(reports_path, f'log_{len(jobs)+1}.txt'), logger, progress])
    #     t0 = time.time()
    #     with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
    #         executor.map(execute_command, jobs)
    #
    #     logger("**execution*ended**")
    #
    #     print(f'Time = {int((time.time()-t0)/60)}')

if __name__ == '__main__':
    enm = pENMUtils('siENM', '5709')

    for key in enm.ips_by_subnet.keys():
        print(f'Subnet {key}')
        ips = enm.ips_by_subnet[key]
        for ip in ips:
            print(f'    {ip}')
    # total = []
    # # for sub in cl.ips_by_subnet.keys():
    # #     print(sub)
    # count = 0
    # for ip in enm.ips_by_subnet['10.247.244.0/22']:
    #     print(f'checking {ip}')
    #     enm.properties_4_host(ip)
    #     # total.append(res)


